{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Image Analysis__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using pyaesthetics. If you use it in your work, please cite:\n",
      "Gabrieli, G., Bornstein, M. H., Setoh, P., & Esposito, G. (2023). Machine learning estimation of users’ implicit and explicit aesthetic judgments of web-pages. Behaviour & Information Technology, 42(4), 392-402.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyaesthetics import analysis_1 as analysis\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to perform analysis on a batch of images and update the results\n",
    "def analyze_batch(batch):\n",
    "    result_list = []\n",
    "    for index, row in batch.iterrows():\n",
    "        file_location = row['file_location']\n",
    "        \n",
    "        # Perform the image analysis\n",
    "        analysis_result = analysis.analyze_image(file_location)  # Assuming this returns a dictionary\n",
    "        \n",
    "        # Flatten the dictionary if there are nested keys (subkeys)\n",
    "        flattened_result = flatten_dict(analysis_result)\n",
    "        # Add the index to track the row for later assignment\n",
    "        flattened_result['index'] = index\n",
    "        \n",
    "        result_list.append(flattened_result)\n",
    "    \n",
    "    return result_list\n",
    "\n",
    "# Function to flatten nested dictionary\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "# Function to process the data in batches of 100 and append the results to a single CSV file\n",
    "def process_images_in_batches(csv_file, output_file=\"FinalImageAnalysisResults.csv\"):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    home_path = \"C:/Users/txtbn\"\n",
    "    df[\"file_location\"] = home_path + df[\"file_location\"].astype(str)\n",
    "    \n",
    "    # Split the DataFrame into batches of 100 rows\n",
    "    batch_size = 100\n",
    "    batches = [df[i:i+batch_size] for i in range(0, len(df), batch_size)]\n",
    "    \n",
    "    # Initialize the process pool and the list to hold final results\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        future_to_batch = {executor.submit(analyze_batch, batch): batch for batch in batches}\n",
    "        \n",
    "        # For each batch, collect results and append to the CSV file\n",
    "        for future in concurrent.futures.as_completed(future_to_batch):\n",
    "            result_list = future.result()\n",
    "            result_df = pd.DataFrame(result_list)\n",
    "            \n",
    "            # Drop the 'index' column (if it exists) before saving to the CSV file\n",
    "            if 'index' in result_df.columns:\n",
    "                result_df = result_df.drop(columns=['index'])\n",
    "            \n",
    "            # Append the batch result to the CSV file\n",
    "            result_df.to_csv(output_file, mode='a', header=not os.path.exists(output_file), index=False)\n",
    "\n",
    "# Call the function to process the images and append results to the same CSV file\n",
    "process_images_in_batches(\"FinalImageData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\txtbn\\AppData\\Local\\Temp\\ipykernel_13668\\3594955736.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"FinalImageDataOutputTotal.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"FinalImageDataOutputTotal.csv\")\n",
    "df.dropna(how = \"all\", axis = 1, inplace = True)\n",
    "df.columns\n",
    "df.to_csv(\"FinalImageDataOutput.csv\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Control Variables__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load sentiment model and tokenizer (Example: 'cardiffnlp/twitter-roberta-base-sentiment')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "# Ensure model is on GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\txtbn\\AppData\\Local\\Temp\\ipykernel_28832\\2025605773.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"FinalImageDataOutputTotal.csv\")\n",
      "C:\\Users\\txtbn\\AppData\\Local\\Temp\\ipykernel_28832\\2025605773.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"caption\"].fillna(\" \", inplace = True)\n",
      "100%|██████████| 119822/119822 [21:48<00:00, 91.60it/s] \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"FinalImageDataOutputTotal.csv\")\n",
    "\n",
    "df[\"caption\"].fillna(\" \", inplace = True)\n",
    "\n",
    "# Sentiment analysis function\n",
    "def sentiment(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return pd.Series([0, 0, 0], index=[\"negative\", \"neutral\", \"positive\"])\n",
    "    \n",
    "    encoded_input = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    scores = output.logits.detach().cpu().numpy()[0]\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    return pd.Series(scores, index=[\"negative\", \"neutral\", \"positive\"])\n",
    "\n",
    "# Apply sentiment analysis with progress bar\n",
    "tqdm.pandas()\n",
    "df[[\"negative\", \"neutral\", \"positive\"]] = df[\"caption\"].progress_apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import emoji\n",
    "import string\n",
    "import re\n",
    "\n",
    "count_emojis = lambda text: emoji.emoji_count(text) if isinstance(text, str) else 0\n",
    "count_words = lambda text: sum(w.strip(string.punctuation).isalpha() for w in text.split()) if isinstance(text, str) else 0\n",
    "count_hashtags = lambda text: len(re.findall(r\"#\", text)) if isinstance(text, str) else 0\n",
    "count_mentions = lambda text: len(re.findall(r\"@\", text)) if isinstance(text, str) else 0\n",
    "\n",
    "df[\"hashtag_count\"] = df[\"caption\"].apply(count_hashtags)\n",
    "df[\"mention_count\"] = df[\"caption\"].apply(count_mentions)\n",
    "df[\"emoji\"] = df[\"caption\"].apply(count_emojis)\n",
    "df[\"length\"] = df[\"caption\"].apply(count_words)\n",
    "df.drop(\"FacesCv2\", axis=1, inplace=True)\n",
    "df.dropna(how = \"all\", axis = 1, inplace = True)\n",
    "df1 = df.dropna(subset = ['Colorfulness_HSV_Colorfulness_HSV', 'Colorfulness_HSV_Mean_H',\n",
    "       'Colorfulness_HSV_Mean_S', 'Colorfulness_HSV_Mean_V',\n",
    "       'Colorfulness_HSV_circular_mean_hue',\n",
    "       'Colorfulness_HSV_circular_std_hue', 'Colorfulness_HSV_color_variety',\n",
    "       'Colorfulness_HSV_std_H', 'Colorfulness_HSV_std_S',\n",
    "       'Colorfulness_HSV_std_V', 'Colorfulness_RGB_Colorfulness_RGB',\n",
    "       'Colorfulness_RGB_Mean_B', 'Colorfulness_RGB_Mean_G',\n",
    "       'Colorfulness_RGB_Mean_R', 'Colorfulness_RGB_std_B',\n",
    "       'Colorfulness_RGB_std_G', 'Colorfulness_RGB_std_R', 'Colors_Aqua',\n",
    "       'Colors_Black', 'Colors_Blue', 'Colors_Fuchsia', 'Colors_Gray',\n",
    "       'Colors_Green', 'Colors_Lime', 'Colors_Maroon', 'Colors_Navy',\n",
    "       'Colors_Olive', 'Colors_Purple', 'Colors_Red', 'Colors_Silver',\n",
    "       'Colors_Teal', 'Colors_White', 'Colors_Yellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to sort alphabetically\n",
    "columns_to_sort = [\n",
    "    'Symmetry_QTD', 'shape_n_line_hor', 'sharpness_sharp_laplacian', 'Colors_Lime',\n",
    "    'Colorfulness_RGB_Mean_R', 'Colorfulness_HSV_Mean_V', 'Colorfulness_HSV_std_V', 'Colors_White',\n",
    "    'Colors_Gray', 'VC_weight', 'Colorfulness_HSV_circular_std_hue', 'Colorfulness_RGB_Mean_G',\n",
    "    'contrast_rms', 'Colors_Red', 'brightness_BT601', 'Colors_Yellow', 'texture_directionality',\n",
    "    'Colorfulness_RGB_std_G', 'Colorfulness_HSV_circular_mean_hue', 'Colorfulness_RGB_Colorfulness_RGB',\n",
    "    'height', 'selfSimilarity_ground', 'Colors_Teal', 'Colors_Silver', 'Colorfulness_HSV_std_S',\n",
    "    'shape_n_line_slant', 'Colors_Blue', 'Colors_Black', 'Colorfulness_HSV_Colorfulness_HSV',\n",
    "    'Colorfulness_HSV_Mean_H', 'Colors_Green', 'Colors_Purple', 'Colorfulness_RGB_std_R',\n",
    "    'Colorfulness_HSV_Mean_S', 'VC_quadTree', 'VC_gradient', 'selfSimilarity_anisotropy',\n",
    "    'Colors_Aqua', 'linesRatio', 'selfSimilarity_parent', 'shape_n_line', 'Colors_Navy',\n",
    "    'selfSimilarity_neighbors', 'contrast_michelson', 'Colors_Olive', 'saturation',\n",
    "    'texture_coarseness', 'Colorfulness_RGB_std_B', 'brightness_BT709', 'Colorfulness_RGB_Mean_B',\n",
    "    'Colors_Fuchsia', 'width', 'Colorfulness_HSV_std_H', 'texture_contrast',\n",
    "    'Colorfulness_HSV_color_variety', 'shape_n_line_ver', 'Colors_Maroon',\n",
    "    'object_count', 'Number_of_Faces_Cv2'\n",
    "]\n",
    "\n",
    "# Sort the specified columns alphabetically\n",
    "df[columns_to_sort] = df[columns_to_sort].reindex(sorted(columns_to_sort), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"FinalImageDataAnalysis.csv\", encoding = \"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Follower Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading JSON File\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"FinalImageDataAnalysis.csv\")\n",
    "\n",
    "def reshape_company_profiles(df):\n",
    "    return df.pivot_table(index='company', columns='platform', values='profile', aggfunc='first').reset_index()\n",
    "\n",
    "df1 = reshape_company_profiles(df)\n",
    "\n",
    "df1[\"facebook_link\"] = df1[\"facebook\"].apply(lambda profile: f\"https://www.facebook.com/{profile}/\")\n",
    "df1[\"twitter_link\"] = df1[\"twitter\"].apply(lambda profile: f\"https://twitter.com/{profile}\")\n",
    "\n",
    "# Load the JSON file\n",
    "print(\"Loading JSON File\")\n",
    "with open(\"twitter_scrape_output.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    tweets_data = json.load(file)\n",
    "\n",
    "# Example DataFrame with Twitter usernames (assuming df1 is already defined)\n",
    "# df1 = pd.DataFrame({'profile': ['UnitedHealthGrp', 'AnotherUser']})\n",
    "\n",
    "# Create a dictionary to store the follower counts\n",
    "follower_counts = {}\n",
    "\n",
    "# Create a set to keep track of processed usernames\n",
    "processed_usernames = set()\n",
    "\n",
    "print(\"Tweets\")\n",
    "# Loop through each tweet in the JSON data with tqdm for progress visualization\n",
    "for tweet in tqdm.tqdm(tweets_data, desc=\"Processing tweets\", unit=\"tweet\"):\n",
    "    # Extract author information with error handling in case some data is missing\n",
    "    author = tweet.get('author', {})\n",
    "    username = author.get('userName')\n",
    "    \n",
    "    # Skip if username is not present or if it has already been processed\n",
    "    if not username or username in processed_usernames:\n",
    "        continue\n",
    "    \n",
    "    # Check if the author's username is in the DataFrame\n",
    "    if username in df1['twitter'].values:\n",
    "        # Get the follower count for this author, with a default if the key is missing\n",
    "        follower_count = author.get('followers', None)\n",
    "        if follower_count is not None:\n",
    "            # Add to dictionary and mark username as processed\n",
    "            follower_counts[username] = follower_count\n",
    "            processed_usernames.add(username)\n",
    "\n",
    "# Add the follower count to the DataFrame, matching by the username\n",
    "df1['follower_count'] = df1['twitter'].map(follower_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"company_profiles.csv\")\n",
    "\n",
    "facebook_followers = pd.read_csv(\"facebook_followers.csv\")\n",
    "instagram_followers = pd.read_csv(\"instagram_followers.csv\")\n",
    "\n",
    "facebook_followers.rename(columns = {\"pageName\": \"facebook\", \"followers\": \"facebook_followers\"}, inplace = True)\n",
    "instagram_followers.rename(columns = {\"username\": \"instagram\",\"followersCount\":\"instagram_followers\"}, inplace = True)\n",
    "df1.rename(columns = {\"follower_count\": \"twitter_followers\"}, inplace = True)\n",
    "\n",
    "df1 = df1.merge(facebook_followers, how=\"left\", on=\"facebook\")\n",
    "df1 = df1.merge(instagram_followers, how=\"left\", on=\"instagram\")\n",
    "\n",
    "df1.to_csv(\"company_profiles.csv\", encoding = \"utf=8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'company', 'facebook', 'instagram', 'twitter',\n",
       "       'facebook_link', 'twitter_link', 'twitter_followers',\n",
       "       'facebook_followers_x', 'instagram_followers_x', 'facebook_followers_y',\n",
       "       'instagram_followers_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\txtbn\\AppData\\Local\\Temp\\ipykernel_17132\\3993931030.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"FinalImageDataAnalysis.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"FinalImageDataAnalysis.csv\")\n",
    "df1 = pd.read_csv(\"company_profiles.csv\")\n",
    "df2 = df1[[\"company\", \"facebook_followers\", \"instagram_followers\", \"twitter_followers\"]]\n",
    "df3 = df.merge(df2, how = \"left\", on = \"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\txtbn\\AppData\\Local\\Temp\\ipykernel_512\\4084682539.py:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"FinalImageDataAnalysis.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"FinalImageDataAnalysis.csv\")\n",
    "df[\"num_comments\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 Images with resizing: 100 seconds\n",
    "10 Images with retaining aspect ratio: 100 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OLD CODE__\n",
    "\n",
    "I was originally using Athec to code for image features but it was incredibly inefficient. Each function reads in the image one at a time, whereas pyaesthetics reads it in once and then conducts the analyses as needed. I have kept the code in case something goes wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colourfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to hold parsed results\n",
    "colorful_hs_values = []\n",
    "colorful_d_values = []\n",
    "contrast_values = []\n",
    "\n",
    "\n",
    "# Iterate over each image path\n",
    "for image in df1[\"file_path\"]:\n",
    "    try:\n",
    "        # Process each image with the color attributes\n",
    "        colorful_hs = color.attr_colorful(image)\n",
    "        colorful_d = color.attr_colorful_emd(image)\n",
    "        contrast = color.attr_contrast_peak(image)\n",
    "\n",
    "        # Append the results for colorful attributes\n",
    "        colorful_hs_values.append(colorful_hs)\n",
    "        colorful_d_values.append(colorful_d)\n",
    "\n",
    "        # Parse the contrast dictionary and collect parsed values\n",
    "        contrast_parsed = parse_measures(contrast)\n",
    "        contrast_values.append(contrast_parsed)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any error gracefully (e.g., invalid image path)\n",
    "        print(f\"Error processing {image}: {e}\")\n",
    "        colorful_hs_values.append(None)\n",
    "        colorful_d_values.append(None)\n",
    "        contrast_values.append(None)\n",
    "\n",
    "# Assign the collected colorful values to new columns\n",
    "df1[\"colorful_hs\"] = colorful_hs_values\n",
    "df1[\"colorful_d\"] = colorful_d_values\n",
    "add_measure_columns(contrast_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'company', 'platform', 'post_id', 'post_date', 'type',\n",
       "       'caption', 'num_likes', 'num_comments', 'num_shares', 'file_path',\n",
       "       'colorful_hs', 'colorful_d', 'contrast_n_peak',\n",
       "       'contrast_peak_distance', 'contrast_peak_list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emap_values = []\n",
    "box_values = []\n",
    "normal_values = []\n",
    "\n",
    "for image in df1[\"file_path\"]:\n",
    "    edges = edge.tf_edge_canny(image)\n",
    "    complexity_emap = edge.attr_complexity_edge(edges)\n",
    "    complexity_box = edge.attr_complexity_edge(edges)\n",
    "    #segment_nc = segment.tf_segment_normalized_cut(image)\n",
    "    #complexity_normal = segment.attr_complexity_segment(segment_nc)\n",
    "\n",
    "    complexity_emap_parsed = parse_measures(complexity_emap)\n",
    "    complexity_box_parsed = parse_measures(complexity_box)\n",
    "    #complexity_normal_parsed = parse_measures(complexity_normal)\n",
    "    \n",
    "    emap_values.append(complexity_emap_parsed)\n",
    "    box_values.append(complexity_box_parsed)\n",
    "    #normal_values.append(complexity_normal_parsed)\n",
    "\n",
    "add_measure_columns(emap_values, method_naming= True)\n",
    "add_measure_columns(box_values, method_naming= True)\n",
    "#add_measure_columns(normal_values, method_naming= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'company', 'platform', 'post_id', 'post_date', 'type',\n",
       "       'caption', 'num_likes', 'num_comments', 'num_shares', 'file_path',\n",
       "       'colorful_hs', 'colorful_d', 'contrast_n_peak',\n",
       "       'contrast_peak_distance', 'contrast_peak_list', 'emap_edge_density',\n",
       "       'emap_edge_distance', 'box_edge_density', 'box_edge_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_values = []\n",
    "\n",
    "for image in df1[\"file_path\"]:\n",
    "    saliency_spiral1 = saliency.tf_saliency_spectral_residual(image)\n",
    "    balance_measure = saliency.attr_ruleofthirds_centroid(saliency_spiral1)\n",
    "    balance_measure_parsed = parse_measures(balance_measure)\n",
    "    balance_values.append(balance_measure_parsed)\n",
    "\n",
    "add_measure_columns(balance_values, method_naming= True)\n",
    "    \n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate measures of rule of thirds based on saliency values that fall within thirds bands and intersections.\n",
    "Return:\n",
    "(1) saliency weights in the two vertical thirds bands and the maximal of the two.\n",
    "(2) saliency weights in the two horizontal thirds bands and the maximal of the two.\n",
    "(3) saliency weights in the four intersection rectangles and the maximal of the four.\n",
    "save_path (optional, default None): str. If provided, a visualization will be saved to this location.\n",
    "'''\n",
    "\n",
    "result = saliency.attr_ruleofthirds_band(saliency_spectral, \n",
    "                                         save_path = os.path.join(tf_folder, \"ruleofthirds band saliency spectral\", imgname) )\n",
    "\n",
    "misc.printd(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Test Code__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.9827\n",
      "2) neutral 0.0087\n",
      "3) negative 0.0086\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "#model.save_pretrained(MODEL)\n",
    "text = \"I am so happy, I love everything, yay\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "# text = \"Covid cases are increasing fast!\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "# Print labels and scores\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
